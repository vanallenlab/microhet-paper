{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Graph Construction Functions</h1>\n",
    "\n",
    "This notebook consists of a collection of functions which can be used for various stages of building graph representations of WSIs with tile-level nodes. Individual functions are given with examples of usage; an end-to-end function which goes straight from WSI to pytorch geometric graph is given in a separate document and is preferable for practical use. Note that some of these functions (especially after node feature extraction) are still rough/may require some data manipulation outside of the provided functions; there is limited cross-compatibility with the end-to-end function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Overview of Necessary Installations</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pip to install the following packages in CLI to the appropriate conda environment/kernel before running \n",
    "\n",
    "#For running hovernet nucleus segmentation\n",
    "# !pip install scanpy\n",
    "# !pip install torchvision\n",
    "# !pip install opencv-python\n",
    "\n",
    "#For running graph construction\n",
    "# !pip install pyflann\n",
    "# !pip install networkx\n",
    "# !pip install torch_sparse, torch_scatter\n",
    "# !pip install git+https://github.com/rusty1s/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General imports \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import skimage \n",
    "from torchvision import models, transforms\n",
    "import itertools\n",
    "import math, random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scanpy as sc\n",
    "from glob import glob\n",
    "import sys,os\n",
    "%matplotlib inline\n",
    "\n",
    "#For hovernet\n",
    "import albumentations as A\n",
    "from pathml.datasets.pannuke import PanNukeDataModule\n",
    "from pathml.ml.hovernet import HoVerNet, loss_hovernet, post_process_batch_hovernet, _HoverNetDecoder\n",
    "from pathml.ml.utils import wrap_transform_multichannel, dice_score\n",
    "from pathml.utils import plot_segmentation\n",
    "\n",
    "#For graph construction\n",
    "from collections import OrderedDict\n",
    "from pyflann import *\n",
    "import skimage.feature\n",
    "import networkx as nx\n",
    "import torchvision.transforms.functional as F\n",
    "import torch_geometric.data as data\n",
    "import torch_geometric.utils as utils\n",
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Nucleus Extraction</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General setup\n",
    "\n",
    "#prepare the model, the GPU, and send the model to the GPU\n",
    "device = torch.device(\"cuda:0\")\n",
    "checkpoint = torch.load(\"/path/to/hovernet_pannuke.pt\", map_location='cpu')\n",
    "\n",
    "n_classes_pannuke = 6\n",
    "\n",
    "hovernet = HoVerNet(n_classes=n_classes_pannuke) #nuclei will be classified into 1 of 6 classes after segmentation\n",
    "hovernet = torch.nn.DataParallel(hovernet) # wrap model to use multi-GPU\n",
    "hovernet.load_state_dict(checkpoint) #load the best checkpoint for prediction/finetuning \n",
    "\n",
    "hovernet = hovernet.module\n",
    "hovernet.to(device);\n",
    "hovernet.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General function set for nucleus segmentation\n",
    "def pil_loader(path):\n",
    "    \"\"\"\n",
    "    Open single image as file to avoid ResourceWarning \n",
    "    (https://github.com/python-pillow/Pillow/issues/835).\n",
    "    \n",
    "    Input: string path name; Output: PIL image.\n",
    "    \n",
    "    (For segmentation purposes, this function is rarely called alone.)\n",
    "    \"\"\"\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "    \n",
    "def as_array(path):\n",
    "    \"\"\"Open single image as np array.\n",
    "    \n",
    "    Input: string path name; Output: np array.\n",
    "    \"\"\"\n",
    "    x = np.asarray(pil_loader(path))\n",
    "    return x \n",
    "\n",
    "def extract_nuclei(df, save_path=None, save_name=None, num_workers=12, **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    This function generates segmentation masks from a tile dataframe.\n",
    "    \n",
    "    Setup: \n",
    "    - Initialize a hovernet PathML model under global variable name hovernet.\n",
    "    - Ensure GPU is prepared and hovernet model is sent to GPU in eval mode.\n",
    "    - Ensure you have proper read/write permissions for any directory you intend\n",
    "    to write your masks to!\n",
    "    \n",
    "    Inputs:\n",
    "    - df: a Pandas DataFrame object containing one row per tile. There should\n",
    "    be one column titled 'full_path' whose entries are the paths to the image \n",
    "    of each tile. \n",
    "    - save_path (optional): string; if specified, this will be the path \n",
    "    to which the segmentation data will be written; this string MUST be an absolute\n",
    "    path and should not contain the file name. If save_path is left blank while \n",
    "    save_name is specified, then the file will be saved to the same directory\n",
    "    in which the function is run (via notebook or script).\n",
    "    - save_name (optional): string; if specified, this will be the filename \n",
    "    to which the segmentation data will be written; this string should not include\n",
    "    a file extension. (File will be written as .npy) Must be specified if save_path\n",
    "    is also specified.\n",
    "    - num_workers (optional): int; number of processes for running inference. \n",
    "    Default is 12.\n",
    "    \n",
    "    Outputs:\n",
    "    - a NumPy array of dimensions (#num tiles, 6, tile_dim, tile_dim) containing \n",
    "    six-channel segmentation masks for each tile (in the order of rows in the \n",
    "    original DataFrame). If save_name is specified, this NumPy array will be saved\n",
    "    to the given path; otherwise, it will be returned. \n",
    "    \"\"\"\n",
    "    #prepare an array of tiles from the df\n",
    "    tiles = np.array([as_array(path) for path in df.full_path.to_numpy()])\n",
    "    #rearrange axes for torch inference\n",
    "    tiles = np.moveaxis(tiles, 3, 1)\n",
    "#     print(tiles.shape)\n",
    "\n",
    "    #Build simple dataloader\n",
    "    tile_data = torch.utils.data.DataLoader(tiles, batch_size=10, num_workers=num_workers)\n",
    "\n",
    "    #pass tiles to the GPU for segmentation inference in small batches\n",
    "    #fill up arrays with predictions. \n",
    "    mask_pred = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(tile_data)):\n",
    "            # send the data to the GPU\n",
    "            images = data.float().to(device)\n",
    "\n",
    "            # pass thru network to get predictions\n",
    "            outputs = hovernet(images)\n",
    "            _, preds_classification = post_process_batch_hovernet(outputs, n_classes=n_classes_pannuke)\n",
    "\n",
    "            #add model results to our prediction-storing arrays\n",
    "            if i == 0:\n",
    "                mask_pred = preds_classification\n",
    "            else:\n",
    "                mask_pred = np.concatenate([mask_pred, preds_classification], axis=0)\n",
    "\n",
    "    #if no save_name specified, return the array. \n",
    "    if save_name is None:\n",
    "        return mask_pred\n",
    "    \n",
    "    #if save_name is given, but no save_path, then save a copy to the local directory. \n",
    "    elif save_path is None:\n",
    "        np.save(save_name + '.npy', mask_pred)\n",
    "    \n",
    "    #if save_name and save_path are given, save the array with the given name to the specified path.\n",
    "    #Hacky loop for creating directories.\n",
    "    else:\n",
    "        for i in range(len(save_path.split('/'))):\n",
    "            try:\n",
    "                #Each time the loop iterates, try making one more nested directory as described in the save_path string.\n",
    "                os.makedirs('/' + '/'.join(dest.split('/')[:i+1]))\n",
    "            except OSError as err:\n",
    "                print(\"OS error: {0}\".format(err))\n",
    "        np.save(save_path + '/' + save_name + '.npy', test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example code block:\n",
    "\n",
    "#prepare the model, the GPU, and send the model to the GPU\n",
    "device = torch.device(\"cuda:0\")\n",
    "checkpoint = torch.load(\"/path/to/hovernet_pannuke.pt\", map_location='cpu')\n",
    "\n",
    "n_classes_pannuke = 6\n",
    "\n",
    "hovernet = HoVerNet(n_classes=n_classes_pannuke) #nuclei will be classified into 1 of 6 classes after segmentation\n",
    "hovernet = torch.nn.DataParallel(hovernet) # wrap model to use multi-GPU\n",
    "hovernet.load_state_dict(checkpoint) #load the best checkpoint for prediction/finetuning \n",
    "\n",
    "hovernet = hovernet.module\n",
    "hovernet.to(device);\n",
    "hovernet.eval();\n",
    "\n",
    "#load in a df of tiles\n",
    "df = pd.read_pickle('010721_Master_df_filtered_TCGA_annotated.pkl')\n",
    "\n",
    "#Run segmentation on tiles for the first 10 WSIs and store to a persistent disk\n",
    "for sample in df.groupby('sample_id').count().index.to_numpy()[:10]:\n",
    "    wsi = df.loc[df.sample_id == sample]\n",
    "    #Although storage-intensive, it is useful to save a copy of slide-specific dfs to ensure a matching order \n",
    "    #of rows in df to tiles to segmentation masks.\n",
    "    wsi.to_pickle('/mnt/disks/data/slide_dfs/'+sample+'.pkl')\n",
    "    extract_nuclei(wsi, save_path='/mnt/disks/data/segmentation_masks/', save_name=sample, num_workers=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature Extraction/Node-building</h3>\n",
    "\n",
    "Each node represents one tile of the WSI, with the following features (averaged across all nuclei in the tile):\n",
    " - (x, y) coordinates of centroid (averaged and used to plot nodes relative to each other in the final graph)\n",
    " - Short axis length \n",
    " - Long axis length\n",
    " - Angle\n",
    " - Area \n",
    " - Arc length\n",
    " - Eccentricity\n",
    " - Roundness\n",
    " - Solidity\n",
    " - Intensity\n",
    " - Dissimilarity\n",
    " - Homogeneity\n",
    " - Energy\n",
    " - ASM\n",
    " \n",
    "Additional neural network features for each tile to be added later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANT GLOBAL VARIABLE FOR NAMING THE FINAL DATAFRAME\n",
    "COLUMNS_LIST = ['sample_id', 'full_path', 'num_nuclei', 'x_coord', 'y_coord', 'avg_short_axis', \n",
    "                'avg_long_axis', 'avg_angle', 'avg_area', 'avg_arc_length', 'avg_eccentricity', 'avg_roundness', \n",
    "                'avg_solidity', 'avg_intensity', 'avg_dissimilarity', 'avg_homogeneity', 'avg_energy', 'avg_ASM']\n",
    "\n",
    "\n",
    "#General function set \n",
    "def compare(image, path, mask):\n",
    "    \"\"\"\n",
    "    Visualize a tile and its corresponding binary mask. \n",
    "    input: np array img of dimensions (size, size, 3), img path string, \n",
    "    np array mask of dimensions (size, size)\n",
    "    \n",
    "    output: nothing returned; matplotlib object created/displayed\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(ncols = 2, figsize = (16, 7))\n",
    "    mask = np.repeat(np.where(mask > 0, 255, 0)[:,:,np.newaxis], 3, axis=2)\n",
    "    name = path.split('/')[-1]\n",
    "    print(f'Image name: {name}')\n",
    "    ax[0].imshow(image)\n",
    "    ax[1].imshow(mask)\n",
    "    ax[0].set_title(\"Tile\")\n",
    "    ax[1].set_title(\"Nucleus mask\")\n",
    "\n",
    "def get_cell_image(img, cx, cy, size=512):\n",
    "    \"\"\"\n",
    "    Extract a \"context-window\" around a specified nucleus of size 64x64px. \n",
    "    \n",
    "    input: np array img of dimensions (size, size, 3), (cx, cy) centroid \n",
    "    coordinates of nucleus, (optional) size param for img size (default 512px)\n",
    "    output: a 64x64px np array. \n",
    "    \"\"\"\n",
    "    cx = 32 if cx < 32 else size - 32 if cx > size - 32 else cx\n",
    "    cy = 32 if cy < 32 else size - 32 if cy > size - 32 else cy\n",
    "    if len(img.shape) == 3:\n",
    "        return img[cy - 32:cy + 32, cx - 32:cx + 32, :]\n",
    "    else:\n",
    "        return img[cy - 32:cy + 32, cx - 32:cx + 32]\n",
    "\n",
    "def get_basic_cell_features(img, grayscale, contour):\n",
    "    \"\"\"\n",
    "    Modified feature extractor for single nucleus basic (non-neural) features.\n",
    "    :param img: np array image\n",
    "    :param grayscale: grayscale version of np array image\n",
    "    :param contour: contour produced from nucleus segmentation (list of (x,y) \n",
    "    coordinates for one nucleus)\n",
    "    \n",
    "    :return: x coordinate, y coordinate of nucleus centroid, concatenated\n",
    "    feature vector for successful contour; None for unsuccessful contour (various\n",
    "    cases apply)\n",
    "    \"\"\"\n",
    "    # Get contour coordinates from contour\n",
    "    \n",
    "    #Contours with fewer than 5 points cannot be fit to ellipse - return None\n",
    "    if contour.shape[0] < 5:\n",
    "        return None\n",
    "    (cx, cy), (short_axis, long_axis), angle = cv2.fitEllipse(contour)\n",
    "    \n",
    "    #contours without valid centroids cannot be processed - return None\n",
    "    if math.isnan(cx) or math.isnan(cy):\n",
    "        return None\n",
    "    cx, cy = int(cx), int(cy)\n",
    "    \n",
    "    # Get a 64 x 64 center crop about each nucleus for GLCM features\n",
    "    img_cell = get_cell_image(grayscale, cx, cy)\n",
    "    img_cell_grey = np.pad(img_cell, [(0, 64 - img_cell.shape[0]), (0, 64 - img_cell.shape[1])],\n",
    "                           mode='reflect')\n",
    "    \n",
    "    # 1. Generate contour features\n",
    "    eccentricity = math.sqrt(1 - (short_axis / long_axis) ** 2)\n",
    "    convex_hull = cv2.convexHull(contour)\n",
    "    area, hull_area = cv2.contourArea(contour), cv2.contourArea(convex_hull)\n",
    "    solidity = float(area) / hull_area\n",
    "    arc_length = cv2.arcLength(contour, True)\n",
    "    \n",
    "    #it's possible in rare cases for the area to be evaluated as 0 - return None, avoid div-by-0 error\n",
    "    if area == 0:\n",
    "        return None\n",
    "    roundness = (arc_length / (2 * math.pi)) / (math.sqrt(area / math.pi))\n",
    "    intensity = get_mean_contour_intensity_grayscale(grayscale, contour)\n",
    "\n",
    "    # 2. Generating GLCM features\n",
    "    out_matrix = skimage.feature.greycomatrix(img_cell_grey, [1], [0])\n",
    "    dissimilarity = skimage.feature.greycoprops(out_matrix, 'dissimilarity')[0][0]\n",
    "    homogeneity = skimage.feature.greycoprops(out_matrix, 'homogeneity')[0][0]\n",
    "    energy = skimage.feature.greycoprops(out_matrix, 'energy')[0][0]\n",
    "    ASM = skimage.feature.greycoprops(out_matrix, 'ASM')[0][0]\n",
    "    # Concatenate + Return all features\n",
    "    x = [[short_axis, long_axis, angle, area, arc_length, eccentricity, roundness, solidity, intensity],\n",
    "         [dissimilarity, homogeneity, energy, ASM]]\n",
    "    return cx, cy, np.array(list(itertools.chain(*x)), dtype=np.float64)\n",
    "\n",
    "def get_mean_contour_intensity_grayscale(gray_img, contours):\n",
    "    \"\"\"\n",
    "    Proxy for how dark/light the pixels are within the segmented nucleus area\n",
    "    :param gray_img: cv2 converted grayscale image of segmented nucleus area\n",
    "    :param contours: contour produced from nucleus segmentation\n",
    "    :return: mean pixel intensity over nucleus contour area\n",
    "    \"\"\"\n",
    "    img_size = gray_img.shape[0]\n",
    "    assert gray_img.shape[0] == gray_img.shape[1]\n",
    "    nucl_mask = np.zeros((img_size, img_size))\n",
    "    cv2.fillPoly(nucl_mask, pts=contours, color=(1.));  # use contour area to make a mask\n",
    "    z = np.ma.masked_array(data=gray_img,\n",
    "                           mask=(nucl_mask != 1.))  # mask masked version to select out only the contour area\n",
    "    return z.compressed().mean()  # take mean grayscale pixel intensity over contour area\n",
    "\n",
    "def tile(slide, masks, i):\n",
    "    \"\"\"\n",
    "    Prepares a single tile for feature extraction. \n",
    "    :param slide: Pandas DataFrame object in which one row represents one tile. Ensure \n",
    "    at least one column in this df has name 'full_path' for accessing tile image, and \n",
    "    one column has name 'sample_id' for identifying from which slide the tiles originate.\n",
    "    :param masks: np array object of dimensions (num_df_rows, tile_dim_1, tile_dim_2)\n",
    "    :param i: indexing integer. Important is that the slide df and the masks array \n",
    "    are ordered identically for corresponding tiles and binary masks to be processed\n",
    "    together; this shouldn't be a problem if previous functions are used. \n",
    "    \n",
    "    :return: np array image of dimensions (tile_dim_1, tile_dim_2, 3); np array mask \n",
    "    of dimensions (tile_dim_1, tile_dim_2); list contours (each element in this list\n",
    "    is a list of (x,y) coordinates, representing the boundary of one nucleus); string \n",
    "    path (full path to image); string sample_id (the associated sample ID for identifying\n",
    "    tiles); x_coord, y_coord of the upper-left-hand corner of the tile (relative to its\n",
    "    position on the WSI)\n",
    "    \"\"\"\n",
    "    #Get image path\n",
    "    path = slide.iloc[i]['full_path']\n",
    "    \n",
    "    #Get out tile x, y coordinates with some very filthy one-liners\n",
    "    x_coord = int(path.split('/')[-1].split('_')[0])\n",
    "    y_coord = path.split('/')[-1].split('_')[1]\n",
    "    y_coord = int(y_coord[:y_coord.find('.')])\n",
    "    \n",
    "    #Retrieve image\n",
    "    image = as_array(path)\n",
    "    #Re-type mask for cv2 to be happy\n",
    "    #This is performed per mask, not for all masks at once, for memory preservation\n",
    "    mask = masks[i].astype('uint8')\n",
    "\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    sample_id = slide.iloc[i]['sample_id']\n",
    "    return image, mask, contours, path, sample_id, x_coord, y_coord\n",
    "\n",
    "def tile_level_feats(contours, image, x_coord, y_coord, tile_size=512):\n",
    "    \"\"\"\n",
    "    Computes features for each nucleus in a tile and averages them to get feature \n",
    "    set for the entire tile. A future version of this function will incorporate\n",
    "    neural-extracted features.\n",
    "    \n",
    "    :param contours: list of all contours (boundaries of nuclei) in a given tile.\n",
    "    :param image: np array of tile, with dimensions (tile_dim_1, tile_dim_2, 3).\n",
    "    :param x_coord: int for x_coord of upper-left-hand corner of tile.\n",
    "    :param y_coord: int for y_coord of upper-left-hand corner of tile.\n",
    "    :param tile_size: (optional) int for tile dimensions. Used for computing average\n",
    "    centroid of tile. Default is 512.\n",
    "    \n",
    "    :return: feature vector as np array; integer count of number of nuclei in tile. \n",
    "    For the rare tile where no nuclei are (successfully) called from the segmentation\n",
    "    mask, a dummy array will be returned with all entries -1, and a count of 0 nuclei. \n",
    "    This tile will then be removed in downstream processing and will not be included \n",
    "    in the final graph. Later versions of this function may elect to keep such tiles, \n",
    "    where neural features can make them more informative for graph analysis.\n",
    "     \n",
    "    \"\"\"\n",
    "    temp_data = []\n",
    "    #Make grayscale image copy\n",
    "    grayscale = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    for contour in contours:\n",
    "        output = get_basic_cell_features(image, grayscale, contour)\n",
    "        if output is not None:\n",
    "            cent_x, cent_y, features = output\n",
    "            \n",
    "            #re-type the data as a list - all lists will have identical len\n",
    "            temp_data.append([cent_x, cent_y] + list(features))\n",
    "    if len(temp_data) == 0:\n",
    "        return np.array([-1 for i in range(15)]), 0\n",
    "    \n",
    "    #the non-ragged list can then be quickly averaged and converted to np array format\n",
    "    result = np.average(np.asarray(temp_data), axis=0)\n",
    "    \n",
    "    #Compute the position for each node by averaging centroids of the tile's nuclei.\n",
    "    result[0] = result[0]/512 + x_coord\n",
    "    result[1] = result[1]/512 + y_coord\n",
    "    return result, len(temp_data)\n",
    "\n",
    "def slide_level_feats(slide, masks):\n",
    "    \"\"\"\n",
    "    Computes features for all tiles in a given slide. \n",
    "    \n",
    "    :param slide: Pandas DataFrame object in which one row represents one tile. Ensure \n",
    "    at least one column in this df has name 'full_path' for accessing tile image, and \n",
    "    one column has name 'sample_id' for identifying from which slide the tiles originate.\n",
    "    Also ensure that this df has tiles for ONLY one slide at a given time. \n",
    "    :param masks: np array object of dimensions (num_df_rows, tile_dim_1, tile_dim_2)\n",
    "    \n",
    "    :return: Pandas Dataframe object in which one row represents one node in graph. \n",
    "    Columns 'slide_id' and 'full_path' can be used to identify tile/WSI of origin; remaining \n",
    "    columns are features of the node. \n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for i in tqdm(range(slide.shape[0])):\n",
    "        #Extract tile data from each row of the df\n",
    "        image, mask, contours, path, sample_id, x_coord, y_coord = tile(slide, masks, i)\n",
    "        #Extract features for the tile\n",
    "        features, num_nuclei = tile_level_feats(contours, image, x_coord, y_coord)\n",
    "        #Add features to data list\n",
    "        data.append([sample_id, path] + [num_nuclei] + list(features))\n",
    "    #Re-type the data list into a DataFrame object\n",
    "    data = pd.DataFrame(data=data, columns=COLUMNS_LIST)\n",
    "    return data\n",
    "\n",
    "def process_whole_slide(wsi, mask_path, save_path=None, save_name=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Computes features for all tiles in a given slide - starting from dataframe or path to dataframe,\n",
    "    and path to array file. \n",
    "    \n",
    "    :param wsi: Can be provided as a string, which will be interpreted as a path to a dataframe pickle\n",
    "    file. Additionally, a dataframe with tiles for a single WSI (only one WSI at a time!) can be passed.\n",
    "    The risk is if the dataframe is built at a different time from the mask array, the order of tiles\n",
    "    may be different. Ensure that the order of rows in the dataframe is reproducible/matches up with \n",
    "    the order of elements inthe mask array. \n",
    "    :param mask_path: A string representing a path to a numpy array of six-channel, default hovernet\n",
    "    segmentation masks. \n",
    "    :param save_path: (optional) string; if specified, this will be the path \n",
    "    to which the segmentation data will be written; this string MUST be an absolute\n",
    "    path and should not contain the file name. If save_path is left blank while \n",
    "    save_name is specified, then the file will be saved to the same directory\n",
    "    in which the function is run (via notebook or script).\n",
    "    :param save_name: (optional) string; if specified, this will be the filename \n",
    "    to which the segmentation data will be written; this string should not include\n",
    "    a file extension. (File will be written as .npy) Must be specified if save_path\n",
    "    is also specified.\n",
    "    \n",
    "    :return: Pandas Dataframe, if save_name is not specified. \n",
    "    \"\"\"\n",
    "    #Setting up slide object\n",
    "    slide = None\n",
    "    if isinstance(wsi, pd.DataFrame):\n",
    "        slide = wsi \n",
    "        slide = slide.reset_index()\n",
    "    else:\n",
    "        slide = pd.read_pickle(wsi)\n",
    "        slide = slide.reset_index()\n",
    "    \n",
    "    #Load mask array, process into binary masks.  \n",
    "    masks = np.load(mask_path)\n",
    "    masks = np.sum(masks, axis=1)\n",
    "    masks = np.where(masks > 0, 255, 0)\n",
    "    \n",
    "    #Write the df object, removing tiles with no nuclei.\n",
    "    #Future versions may give option to keep tiles with no nuclei if they have additional features \n",
    "    #(e.g. ResNet feature vector representation)\n",
    "    nodes = slide_level_feats(slide, masks)\n",
    "    nodes = nodes.loc[nodes.num_nuclei > 0]\n",
    "    \n",
    "    #if no save_name specified, return the array. \n",
    "    if save_name is None:\n",
    "        return nodes\n",
    "    \n",
    "    #if save_name is given, but no save_path, then save a copy to the local directory. \n",
    "    elif save_path is None:\n",
    "        nodes.to_pickle(save_name + '.pkl')\n",
    "    \n",
    "    #if save_name and save_path are given, save the array with the given name to the specified path.\n",
    "    #Hacky loop for creating directories.\n",
    "    else:\n",
    "        for i in range(len(save_path.split('/'))):\n",
    "            try:\n",
    "                #Each time the loop iterates, try making one more nested directory as described in the save_path string.\n",
    "                os.makedirs('/' + '/'.join(dest.split('/')[:i+1]))\n",
    "            except OSError as err:\n",
    "                print(\"OS error: {0}\".format(err)) \n",
    "        nodes.to_pickle(save_path + '/' + save_name + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example code block:\n",
    "\n",
    "#IMPORTANT GLOBAL VARIABLE FOR NAMING THE FINAL DATAFRAME\n",
    "COLUMNS_LIST = ['sample_id', 'full_path', 'num_nuclei', 'x_coord', 'y_coord', 'avg_short_axis', \n",
    "                'avg_long_axis', 'avg_angle', 'avg_area', 'avg_arc_length', 'avg_eccentricity', 'avg_roundness', \n",
    "                'avg_solidity', 'avg_intensity', 'avg_dissimilarity', 'avg_homogeneity', 'avg_energy', 'avg_ASM']\n",
    "\n",
    "#Set up df and mask directories\n",
    "df_dir = sorted(glob('/mnt/disks/data/slide_dfs/*'))\n",
    "mask_dir = sorted(glob('/mnt/disks/data/segmentation_masks/*'))\n",
    "\n",
    "#Store all data in a single large df\n",
    "all_nodes = None\n",
    "\n",
    "#Run node feature extraction for first 10 slides\n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        all_nodes = process_whole_slide(df_dir[i], mask_dir[i]) \n",
    "    else:\n",
    "        all_nodes = pd.concat([all_nodes, process_whole_slide(df_dir[i], mask_dir[i])], ignore_axis=True)\n",
    "\n",
    "all_nodes.to_pickle('/mnt/disks/data/graph_nodes.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Graph-building</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General function set \n",
    "def df2graph(df):\n",
    "    \"\"\"\n",
    "    This function takes in a dataframe with columns ordered as follows:\n",
    "        \n",
    "        ['full_path', 'x_coord', 'y_coord', 'num_nuclei', 'avg_short_axis',\n",
    "       'avg_long_axis', 'avg_angle', 'avg_area', 'avg_arc_length',\n",
    "       'avg_eccentricity', 'avg_roundness', 'avg_solidity', 'avg_intensity',\n",
    "       'avg_dissimilarity', 'avg_homogeneity', 'avg_energy', 'avg_ASM',\n",
    "       'class_1_prob'] - index column is 'slide_id'\n",
    "       \n",
    "    NOTE: You may need to reorder/drop some columns if you use this function\n",
    "    on a raw dataframe of nodes. This format is ESSENTIAL to ensuring that \n",
    "    only numerical features get added for each node in the graph, which prevents\n",
    "    huge ugly torch-typing errors from the downstream conversion of networkx graphs\n",
    "    to pytorch-geometric graphs. \n",
    "       \n",
    "    It returns a networkx Graph object in which nodes are the avg-centroids \n",
    "    of tiles (with coordinates [node_x, node_y]) and features are all numerical\n",
    "    values except for the coords (not incl. full_path or slide_id)\n",
    "       \"\"\"\n",
    "    \n",
    "    \"\"\"Silly bunch of code, but here's what happens. \n",
    "    -First, drop NaNs as necessary, then reset index.\n",
    "    -Sort nodes so that they appear top-bottom, left-right relative to \n",
    "    their position on the WSI (makes for more organized graph node names)\n",
    "    -Do it again (???) - the tile sorting won't stick unless you do. \n",
    "    -Re-index on the new sorted order of rows, overwriting the original indexes\n",
    "    of the rows (before sorting). \n",
    "    -Delete the old indexes (which get pushed to a column titled 'index')\"\"\"\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index()\n",
    "    df = df.sort_values(by=['node_x', 'node_y'])\n",
    "    df = df.reset_index()\n",
    "    df = df.sort_values(by=['node_x', 'node_y'])\n",
    "    df = df.reindex([i for i in range(df.shape[0])])\n",
    "    df = df.drop(labels=['index'], axis=1)\n",
    "\n",
    "    #initialize graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    #use iterrows method - index will be node name, features and centroid will be extracted appropriately\n",
    "    for v, node in df.iterrows():\n",
    "        G.add_node(v, centroid=np.array([node['node_x'], node['node_y']], dtype=np.float32), x=node[3:].to_numpy(dtype=np.float32))\n",
    "    \n",
    "    return G\n",
    "\n",
    "def KNN(G):\n",
    "    \"\"\"Condensed version of KNN which adds edges to graph.\"\"\"\n",
    "    #Code directly transplanted from pathomic-fusion notebook \n",
    "    #First, build a \"dataset\"  using the centroid data - collect node data into a new array\n",
    "    centroids = []\n",
    "    for u, attrib in G.nodes(data=True):\n",
    "        centroids.append(attrib['centroid'])\n",
    "\n",
    "    cell_centroids = np.array(centroids).astype(np.float64)\n",
    "    dataset = cell_centroids\n",
    "\n",
    "\n",
    "    start = None\n",
    "\n",
    "    #Run K-means\n",
    "    for idx, attrib in tqdm(list(G.nodes(data=True))):\n",
    "        start = idx\n",
    "\n",
    "        #initialize the FLANN object \n",
    "        flann = FLANN()\n",
    "\n",
    "        #Add one node's worth of edges to the graph at a time \n",
    "        testset = np.array([attrib['centroid']]).astype(np.float64)\n",
    "\n",
    "        #Calculate edges \n",
    "        results, dists = flann.nn(dataset, testset, num_neighbors=5, algorithm = 'kmeans', branching = 32, iterations = 100, checks = 16)\n",
    "        results, dists = results[0], dists[0]\n",
    "        nns_fin = []\n",
    "       # assert (results.shape[0] < 6)\n",
    "\n",
    "        #Use results to draw in edges in the graph \n",
    "        for i in range(1, len(results)):\n",
    "            G.add_edge(idx, results[i], weight = dists[i])\n",
    "            nns_fin.append(results[i])\n",
    "\n",
    "    return G\n",
    "\n",
    "def from_networkx(G):\n",
    "    r\"\"\"Converts a :obj:`networkx.Graph` or :obj:`networkx.DiGraph` to a\n",
    "    :class:`torch_geometric.data.Data` instance.\n",
    "    Args:\n",
    "        G (networkx.Graph or networkx.DiGraph): A networkx graph.\n",
    "    \"\"\"\n",
    "\n",
    "    G = G.to_directed() if not nx.is_directed(G) else G\n",
    "    edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "\n",
    "    keys = []\n",
    "    keys += list(list(G.nodes(data=True))[0][1].keys())\n",
    "    keys += list(list(G.edges(data=True))[0][2].keys())\n",
    "    data = {key: [] for key in keys}\n",
    "\n",
    "    for _, feat_dict in G.nodes(data=True):\n",
    "        for key, value in feat_dict.items():\n",
    "            print(value) if count==0 else None\n",
    "            data[key].append(value)\n",
    "    for _, _, feat_dict in G.edges(data=True):\n",
    "        for key, value in feat_dict.items():\n",
    "            data[key].append(value)\n",
    "\n",
    "    #Hopefully I can re-type the final dictionary value manually to avoid issues\n",
    "    weights = data['weight']\n",
    "    weights = [float(x) for x in weights]\n",
    "    # weights = np.array(weights)\n",
    "    data['weight'] = weights\n",
    "\n",
    "    # THIS IS THE PROBLEMATIC PART\n",
    "    for key in data.keys():\n",
    "        data[key] = torch.tensor(data[key])\n",
    "    #     print(key)\n",
    "\n",
    "    data['edge_index'] = edge_index\n",
    "    data = torch_geometric.data.Data.from_dict(data)\n",
    "    data.num_nodes = G.number_of_nodes()\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_to_pytorch_geometric(G, save_path='test', **kwargs):\n",
    "    \"\"\"\n",
    "    Code block for writing the networkx graph into a pytorch geometric graph, and then saving it.\n",
    "    Note - the save_path parameter should NOT have a filename extension to it. \"\"\"\n",
    "    G = from_networkx(G)\n",
    "\n",
    "    edge_attr_long = (G.weight.unsqueeze(1)).type(torch.LongTensor)\n",
    "    G.edge_attr = edge_attr_long \n",
    "\n",
    "    edge_index_long = G['edge_index'].type(torch.LongTensor)\n",
    "    G.edge_index = edge_index_long\n",
    "\n",
    "    x_float = G['x'].type(torch.FloatTensor)\n",
    "    G.x = x_float\n",
    "\n",
    "    G['weight'] = None\n",
    "    G['nn'] = None\n",
    "    torch.save(G, save_path+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
