{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from checkmate_imports import *\n",
    "\n",
    "# global variables \n",
    "HUE_ORDER = ['stroma','pred_g2','intermediate_grade','pred_g4']\n",
    "MIN_SEGMENT_SIZE = 50\n",
    "GRADE_DIFF_THRESH = 0.35\n",
    "TUMOR_DIFF_THRESH = 0.35\n",
    "MIN_TUMOR_SEG_MEAN = 0.70\n",
    "NODE_DIFF_CUTOFF = invert_rag_weight(GRADE_DIFF_THRESH)\n",
    "TILES_PER_MM2 = 0.256**-2\n",
    "\n",
    "MIN_TIL_COUNT = 10\n",
    "TIL_ISO_CUTOFF = 14  # based on none vs any AUROC bootstrap on high grade foci + no hard cases\n",
    "TIL_HIGH_CUTOFF = 48 # based on not-high vs high AUROC bootstrap on high grade foci + no hard cases\n",
    "FRAC_CUTOFF = 0.25\n",
    "TIL_AREA_CUTOFF = 10\n",
    "\n",
    "# assume 7x7 minimum case for a square area focus\n",
    "# going 2 tiles inner would result in a 5x5 inner cube and thus area cutoff of 25\n",
    "# MIN_CENTER_AREA = 25\n",
    "MIN_CENTER_AREA = 10  # relaxing from 25 to try to recover possible interesting foci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.read_csv('./rerun_patientlevel_harmonized_annotations.csv', index_col=0)\n",
    "assigned_df = pd.read_pickle('./rerun_smoothed_tile_level_info.pkl')  # tile level smoothed p(tumor) and p(g4 not g2) for all cohorts\n",
    "assigned_df['full_path'] = assigned_df['full_path'].str.replace('tcga-kidney-tiles', 'kirc')\n",
    "\n",
    "# 20210624NB run on GPU VM using dask `summarize_nucleus_calls_dask_manual_intensity_til_only`\n",
    "summaries = pd.read_csv('/home/jupyter/20210624NB_aggregating_cm025_nuclei_summaries_both_arms.csv')\n",
    "\n",
    "# this is the full cm025 annotation set\n",
    "anno = pd.read_csv('/home/jupyter/manual_cm025_merged_braunsupp_annotations.csv') \n",
    "anno['unique_id'] = 'cm025_' + anno.subjid.astype(str)\n",
    "anno['ImmunoPhenotype'].value_counts()\n",
    "\n",
    "paper_desert = anno.loc[anno.ImmunoPhenotype == 'Desert','unique_id'].values\n",
    "paper_infl = anno.loc[anno.ImmunoPhenotype == 'Infiltrated','unique_id'].values\n",
    "paper_excl = anno.loc[anno.ImmunoPhenotype == 'Excluded','unique_id'].values\n",
    "anno = anno.set_index('unique_id')\n",
    "\n",
    "combined_metrics = metrics.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather two-stage watershed outputs from generic runner\n",
    "- `full_rerun_all_cohorts_seg_rerun_070_tumor_segmean.py`: Generation of two-stage segmentation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_outs = {}\n",
    "for cohort in ['cm025','kirc','profile']:\n",
    "    seg_outs[cohort] = torch.load(f'rerun_{cohort}_twostage_watershed_out_rerun.pkl')\n",
    "\n",
    "seg_out_agg = {}\n",
    "failed_ids = []\n",
    "failed_data_agg = {}\n",
    "for cohort, seg_out_data in seg_outs.items():\n",
    "    for entry in seg_out_data:\n",
    "        try:\n",
    "            unique_id = entry['unique_id']\n",
    "            seg_out_agg[unique_id] = entry\n",
    "        except:\n",
    "            uid = entry['seg_df']['unique_id'].unique()[0]\n",
    "            failed_ids.append(uid)\n",
    "            failed_data_agg[uid] = entry['seg_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1297"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seg_out_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save tile level info DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tilewise_nontil_info = [] \n",
    "for unique_id, outs in seg_out_agg.items():\n",
    "    try:\n",
    "        tilewise_nontil_info.append(outs['seg_df'].copy())\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "tilewise_nontil_info = pd.concat(tilewise_nontil_info).reset_index()\n",
    "# tilewise_nontil_info = tilewise_nontil_info.loc[tilewise_nontil_info['seg_label'] != 'all_tumor']  # TCTM legacy not needed\n",
    "tilewise_nontil_info = tilewise_nontil_info.drop_duplicates(['unique_id','x','y'])\n",
    "tilewise_nontil_info = tilewise_nontil_info.set_index(['unique_id'])\n",
    "tilewise_nontil_info.to_csv('./rerun_all_cohorts_passing_twostage_segmentation_tile_level_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Omitted: `20210826_cm025_tctm_calling_all_cohorts.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate RAG edge information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_type = 'premerge_expansion_rags'\n",
    "\n",
    "# initially based on 20210513 NB on pivoting to get counts of edge types\n",
    "count_store = []\n",
    "weighted_edge_info_store= []\n",
    "merged_descriptions = []\n",
    "node_summaries = {}\n",
    "processed_graphs = {}\n",
    "\n",
    "\n",
    "for uid, outs in seg_out_agg.items():\n",
    "    rags = deepcopy(outs[rag_type])\n",
    "    rags[0] = outs['rag']\n",
    "\n",
    "    for dist, entry in rags.items():\n",
    "        g = entry.copy()\n",
    "        g = post_process_seg_graph_simplified(g, uid, MIN_SEGMENT_SIZE, NODE_DIFF_CUTOFF)\n",
    "        \n",
    "        if dist == 0: # store info derived from base graph only; we only need the others for edge related info\n",
    "            processed_graphs[uid] = g\n",
    "            node_summaries[uid] = summarize_nodes(g, outs['seg_df'])\n",
    "\n",
    "        if len(g.edges) > 0:\n",
    "            edge_desc = pd.DataFrame({k:v for k,v in g.edges.items()}).transpose()\n",
    "            edge_desc.index = edge_desc.index.set_names(['edge0','edge1'])\n",
    "            edge_desc['unique_id'] = uid\n",
    "            edge_desc['expansion_dist'] = dist\n",
    "            weighted_edge_info_store.append(reset_set_idx(edge_desc, ['unique_id','expansion_dist','edge0','edge1']))\n",
    "        \n",
    "weighted_edge_info_store = pd.concat(weighted_edge_info_store)\n",
    "weighted_edge_info_store['min_node_area'] = weighted_edge_info_store[['node0_tumor_area_frac','node1_tumor_area_frac']].min(1)\n",
    "weighted_edge_info_store['edge_set'] = weighted_edge_info_store.reset_index()[['edge0','edge1']].apply(lambda x: set(x),1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9685, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_edge_info_store.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate RAG edges into \"proximal\" vs \"distal\" categories\n",
    "- Collapse default and expansion distance 1 into \"proximal\"\n",
    "- Collapse expansion distance 10 & 25 into \"distal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_class_agg = []\n",
    "for uid in weighted_edge_info_store.index.levels[0]:\n",
    "    ex_out = seg_out_agg[uid]\n",
    "    seg_df = ex_out['seg_df']\n",
    "    edge_subset = weighted_edge_info_store.loc[[uid]]\n",
    "    edge_subset = check_label_set_df(seg_df, edge_subset)\n",
    "    edge_class_agg.append(edge_subset)\n",
    "    \n",
    "edge_class_agg = pd.concat(edge_class_agg)\n",
    "\n",
    "# fix object dtype assignment\n",
    "for col in edge_class_agg.columns:\n",
    "    try:\n",
    "        edge_class_agg[col] = edge_class_agg[col].astype(float)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "edge_class_agg_pivot = edge_class_agg.reset_index().pivot_table(index=['unique_id','edge0','edge1','passing_edge'], columns='expansion_dist', values='diff')\n",
    "edge_class_agg_pivot = edge_class_agg_pivot.reset_index(level=3)\n",
    "edge_class_agg_pivot['passing_edge'] = edge_class_agg_pivot['passing_edge'].astype(bool)\n",
    "edge_class_agg_pivot.loc[edge_class_agg_pivot.passing_edge, 'edge_class'] = edge_class_agg_pivot.loc[edge_class_agg_pivot.passing_edge].apply(lambda x: classify_distal_vs_proximal_edge(x), 1)\n",
    "edge_class_agg_pivot['edge_class'] = edge_class_agg_pivot['edge_class'].fillna('not_eligible')\n",
    "\n",
    "edge_class_sum = pd.get_dummies(edge_class_agg_pivot, columns=['edge_class']).groupby('unique_id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_class_sum.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrate previous 20210708 TIL info upstream of iterating through RAGs for further annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cols = ['tumor_counts','til_counts','stroma_counts']\n",
    "summary_derived_cols = ['stroma_tumor_ratio','stroma_til_ratio','tumor_counts','til_counts','stroma_counts']\n",
    "\n",
    "tilewise_til_info = merge_nonoverlapping(tilewise_nontil_info.set_index(['x','y'],append=True), summaries.rename(columns={'tx':'x', 'ty':'y'}).set_index(['unique_id','x','y']))\n",
    "tilewise_til_info = tilewise_til_info.loc[tilewise_til_info.index.levels[0].intersection(summaries.unique_id.unique())]\n",
    "tilewise_til_info[count_cols]  = tilewise_til_info[count_cols].fillna(0)  # tiles with 0 TIL counts need to be filled \n",
    "\n",
    "tilewise_nontil_inforegation = tilewise_til_info.groupby(['unique_id','merged_labels']).aggregate(['mean','std','count'])\n",
    "tilewise_nontil_info_filtered = tilewise_nontil_inforegation.loc[tilewise_nontil_inforegation['til_counts']['count'] > MIN_SEGMENT_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key: get % of area in a given segment that is above TIL_ISO_CUTOFF\n",
    "til_context_agg = tilewise_til_info.groupby(['unique_id','merged_labels'])[['til_counts']].apply(lambda x: (x > TIL_ISO_CUTOFF).sum())\n",
    "til_context_agg = til_context_agg.rename(columns={'til_counts':'tiles_above_til_cutoff'}).join(tilewise_nontil_info_filtered['til_counts']['count'])\n",
    "til_context_agg = til_context_agg.dropna()\n",
    "til_context_agg['til_status_label_exp'] = til_context_agg.apply(lambda x: assign_til_status_label_exp(x['tiles_above_til_cutoff'], x['count'], frac_cutoff=FRAC_CUTOFF, tile_area_cutoff=TIL_AREA_CUTOFF), 1)\n",
    "\n",
    "# assign low vs high (can be redundant if only using a single cutoff)\n",
    "til_status = tilewise_nontil_info_filtered['til_counts']['mean'].apply(lambda x: assign_til_status_label(x, TIL_ISO_CUTOFF, TIL_HIGH_CUTOFF))\n",
    "til_status.name = 'til_status_basic'\n",
    "til_context_agg = til_context_agg.join(til_status)\n",
    "\n",
    "# again, redundant if we only use one cutoff\n",
    "til_context_agg.loc[(til_context_agg['til_status_label_exp'] == 'dispersed_infiltration') & (til_context_agg['til_status_basic'] == 'highly_infiltrated'), 'til_status_combined'] = 'highly_infiltrated_dispersed'\n",
    "til_context_agg.loc[(til_context_agg['til_status_label_exp'] == 'dispersed_infiltration') & (til_context_agg['til_status_basic'] == 'intermed_infiltrated'), 'til_status_combined'] = 'intermed_infiltrated_dispersed'\n",
    "til_context_agg.loc[(til_context_agg['til_status_label_exp'] == 'dispersed_infiltration') & (til_context_agg['til_status_basic'] == 'non_infiltrated'), 'til_status_combined'] = 'low_infiltrated_dispersed'\n",
    "til_context_agg.loc[(til_context_agg['til_status_label_exp'] == 'localized_infiltration'), 'til_status_combined'] = 'localized_infiltration'\n",
    "til_context_agg.loc[(til_context_agg['til_status_label_exp'] == 'non_infiltrated'), 'til_status_combined'] = 'non_infiltrated'\n",
    "\n",
    "# add actual TIL counts/avgs back\n",
    "til_context_agg = til_context_agg.join(tilewise_til_info.groupby(['unique_id','merged_labels'])['til_counts'].mean()).rename(columns={'til_counts':'til_counts_tile_avg', 'count':'tile_count'}) \n",
    "\n",
    "til_context_agg_piv = til_context_agg.reset_index().value_counts(subset=['unique_id','til_status_combined'])\n",
    "til_context_agg_piv.name = 'cat_counts'\n",
    "til_context_agg_piv  = pd.DataFrame(til_context_agg_piv.reset_index())\n",
    "til_context_agg_piv = til_context_agg_piv.pivot_table(index='unique_id', columns=['til_status_combined'], values='cat_counts').fillna(0)\n",
    "til_context_agg_piv['any_dispersed'] = til_context_agg_piv[[x for x in til_context_agg_piv.columns if 'dispersed' in x]].sum(1)\n",
    "til_context_agg['til_cutoff'] = TIL_ISO_CUTOFF\n",
    "\n",
    "contrast_candidates = get_indices(til_context_agg.groupby('unique_id').til_status_combined.apply(lambda x: np.any(x == 'non_infiltrated') & np.any(np.isin(x, ['intermed_infiltrated_dispersed', 'highly_infiltrated_dispersed']))))\n",
    "\n",
    "context_mapper = {\n",
    "    'til_contrast_category': ['non_infiltrated_bordering_localized',\n",
    "                             'contrasting_dispersed_highly_bordering_intermed',\n",
    "                             'contrasting_dispersed_intermed_bordering_highly',\n",
    "                             'non_infiltrated_bordering_dispersed',\n",
    "                             'localized_bordering_dispersed'],\n",
    "    'combined_edge_context': ['lower_grade_non_infiltrated_higher_grade_localized','higher_grade_non_infiltrated_lower_grade_localized',\n",
    "                             'lower_grade_non_infiltrated_higher_grade_dispersed','higher_grade_non_infiltrated_lower_grade_dispersed',\n",
    "                             'lower_grade_localized_higher_grade_dispersed','higher_grade_localized_lower_grade_dispersed',\n",
    "                              'lower_grade_more_infiltrated_both_dispersed','higher_grade_more_infiltrated_both_dispersed'\n",
    "                             ],\n",
    "    'general_edge_context': ['lower_grade_more_infiltrated','higher_grade_more_infiltrated']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add additional post-processing (TIL, etc) info, aggregate counts for discrete descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# 20210513 NB on pivoting to get counts of edge types\n",
    "count_store = []\n",
    "merged_descriptions = []\n",
    "# tilewise_nontil_info = tilewise_nontil_info.set_index('unique_id')\n",
    "\n",
    "# for uid in til_context_agg.index.levels[0]: # one case doesn't overlap\n",
    "for uid in til_context_agg.index.get_level_values(0).unique():\n",
    "    g = processed_graphs[uid].copy()\n",
    "    g = add_TIL_info(g, til_context_agg.loc[uid])\n",
    "    summary = summarize_nodes(g, tilewise_nontil_info.loc[uid])\n",
    "    \n",
    "    counts = pd.DataFrame()\n",
    "    for col in ['til_contrast_category','general_edge_context','combined_edge_context']:\n",
    "        temp_agg = [v[col] for k,v in g.edges.items() if col in v.keys()]\n",
    "        temp_agg = pd.Series(temp_agg, name=col).astype('category')\n",
    "        temp_agg = temp_agg.value_counts()\n",
    "        temp_agg.name = col+'_count'\n",
    "        temp_agg = pd.DataFrame(temp_agg)\n",
    "        temp_agg['unique_id'] = uid\n",
    "        temp_agg.index.name = col\n",
    "        temp_agg = temp_agg.pivot_table(columns=col, index='unique_id')\n",
    "        counts = pd.concat([counts, temp_agg], 1)\n",
    "    count_store.append(counts)\n",
    "\n",
    "    merged_node_desc = summary['seg_df'].join(til_context_agg.loc[uid])\n",
    "    merged_node_desc['unique_id'] = uid\n",
    "    merged_descriptions.append(merged_node_desc.set_index(['unique_id'], append=True).reorder_levels([1,0]))\n",
    "          \n",
    "count_store = pd.concat(count_store).fillna(0)\n",
    "merged_descriptions = pd.concat(merged_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe stromal infiltration [basic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "localized_infiltration    383\n",
       "dispersed_infiltration    122\n",
       "non_infiltrated            50\n",
       "Name: stroma_til_status, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroma_til_mapper = {\n",
    "    'low_infiltrated_dispersed':'dispersed_infiltration',\n",
    "    'intermed_infiltrated_dispersed':'dispersed_infiltration',\n",
    "    'highly_infiltrated_dispersed':'dispersed_infiltration',\n",
    "    'non_infiltrated':'non_infiltrated',\n",
    "    'localized_infiltration':'localized_infiltration',\n",
    "\n",
    "}\n",
    "stromal_til_description_basic = til_context_agg.loc[(slice(None),0),:].til_status_combined.map(stroma_til_mapper)\n",
    "stromal_til_description_basic.name = 'stroma_til_status'\n",
    "stromal_til_description_basic = stromal_til_description_basic.reset_index(level=1, drop=True)\n",
    "stromal_til_description_basic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define general isolation+infiltration status labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "slidemean = tilewise_til_info.loc[tilewise_til_info.meta !='stroma'].groupby('unique_id').mean()\n",
    "\n",
    "iso_desc = []\n",
    "for uid in merged_descriptions.index.levels[0]:\n",
    "    x = merged_descriptions.loc[uid,['smoothed_prob_g4_not_g2', 'connection_category', 'degree','tiles_above_til_cutoff','tile_count','til_counts_tile_avg','til_status_combined']]\n",
    "    x = x.join(compare_nodes(merged_descriptions.loc[uid], slidemean.loc[uid],'smoothed_prob_g4_not_g2'))\n",
    "    x.loc[x.connection_category=='isolated'][['connection_category','til_status_combined','rel_grade_label']].apply(lambda x: '_'.join(x), 1).values\n",
    "    x['unique_id'] = uid\n",
    "    iso_desc.append(x.set_index(['unique_id'], append=True).reorder_levels([1,0]))\n",
    "iso_desc = pd.concat(iso_desc)\n",
    "\n",
    "iso_combined_labels = iso_desc.loc[iso_desc.connection_category=='isolated'][['connection_category','til_status_combined','rel_grade_label']].apply(lambda x: '_'.join(x), 1)\n",
    "iso_desc.loc[iso_desc.connection_category=='isolated', 'isolation_til_status'] = iso_combined_labels\n",
    "isolation_til_status_cats = iso_desc.isolation_til_status.dropna().unique()\n",
    "iso_desc['isolation_til_status'] = iso_desc['isolation_til_status'].astype('category')\n",
    "\n",
    "iso_counts = pd.DataFrame()\n",
    "for uid, df in iso_desc.groupby('unique_id'):\n",
    "    y = df['isolation_til_status'].value_counts()\n",
    "    y.name = uid\n",
    "    y = pd.DataFrame(y)\n",
    "    iso_counts = pd.concat([iso_counts, y.transpose()])\n",
    "\n",
    "updated_count_stats = pd.concat([count_store['combined_edge_context_count'], iso_counts], 1)\n",
    "\n",
    "# updated_count_stats = pd.concat([pd.concat([count_store[x] for x in count_store.columns.levels[0]], 1), iso_counts], 1)\\\n",
    "updated_count_stats['isolated_infiltrated_total'] = iso_counts[[x for x in iso_counts.columns if 'non_infiltrated' not in x]].sum(1)\n",
    "updated_count_stats['isolated_non_infiltrated_total'] = iso_counts[[x for x in iso_counts.columns if 'non_infiltrated' in x]].sum(1)\n",
    "\n",
    "iso_desc['is_isolated'] = iso_desc['connection_category'] == 'isolated'\n",
    "iso_desc['is_infiltrated'] = iso_desc['til_status_combined'] != 'non_infiltrated'\n",
    "iso_desc['general_iso_inf_status'] = iso_desc['is_isolated'].map({True:'isolated',False:'nonisolated'}) + '_' + iso_desc['is_infiltrated'].map({True:'infiltrated',False:'noninfiltrated'})\n",
    "iso_desc['general_iso_inf_status'].value_counts()\n",
    "iso_desc['general_iso_inf_status'] = iso_desc['general_iso_inf_status'].astype('category')\n",
    "\n",
    "updated_count_stats = pd.concat([updated_count_stats, aggregate_counts(iso_desc, 'general_iso_inf_status')], 1)\n",
    "\n",
    "generic_combined_labels = iso_desc[['til_status_combined','rel_grade_label']].fillna('no_info').apply(lambda x: '_'.join(x), 1)\n",
    "infiltration_cats = generic_combined_labels.loc[(~generic_combined_labels.str.startswith('non_infiltrated')) & (~generic_combined_labels.str.startswith('no_info'))].unique()\n",
    "non_infiltration_cats = generic_combined_labels.loc[(generic_combined_labels.str.startswith('non_infiltrated'))].unique()\n",
    "infiltration_cats_mapper = {x: 'infiltrated_' + '_'.join(x.split('_')[-3:]) for x in infiltration_cats}\n",
    "\n",
    "for entry in non_infiltration_cats:\n",
    "    infiltration_cats_mapper[entry] = entry\n",
    "\n",
    "iso_desc['general_node_infiltration_rel_grade'] = generic_combined_labels.map(infiltration_cats_mapper).astype('category')\n",
    "general_counts = aggregate_counts(iso_desc, 'general_node_infiltration_rel_grade')\n",
    "updated_count_stats = pd.concat([updated_count_stats, general_counts], 1)\n",
    "simple_iso_inf_cats = ['nonisolated_noninfiltrated', 'isolated_infiltrated', 'isolated_noninfiltrated', 'nonisolated_infiltrated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define groups of features and create formulas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "til_semantic_cols = ['highly_infiltrated_dispersed', 'intermed_infiltrated_dispersed',\n",
    "       'localized_infiltration', 'low_infiltrated_dispersed',\n",
    "       'non_infiltrated']\n",
    "\n",
    "rag_feature_cols = ['major_diff_edge_count',\n",
    "       'minor_diff_edge_count', 'largest_cc_size', 'avg_degree',\n",
    "       'high_amidst_low_count', 'high_bordering_low_count', 'isolated_count',\n",
    "       'low_amidst_high_count', 'low_bordering_high_count',\n",
    "       ]\n",
    "\n",
    "combined_info_cols = [\n",
    "    'combined_rag_differential_label','total_foci_infiltration_label'\n",
    "]\n",
    "\n",
    "\n",
    "rag_feature_formula = ' + '.join(rag_feature_cols)\n",
    "til_semantic_feature_formula = ' + '.join(til_semantic_cols)\n",
    "combined_feature_formula = ' + '.join(combined_info_cols)\n",
    "general_iso_inf_formula = ' + '.join(list(iso_desc['general_iso_inf_status'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_comparison = []\n",
    "for iso_cutoff in [TIL_ISO_CUTOFF]:\n",
    "# for iso_cutoff in [5, 10, 25]:\n",
    "    df = pd.DataFrame()\n",
    "    temp_overall = (tilewise_til_info['til_counts'] > iso_cutoff).groupby('unique_id').mean()\n",
    "    temp_overall.name = 'overall_til_fraction'\n",
    "    temp_tumor = (tilewise_til_info.loc[tilewise_til_info.meta !='stroma']['til_counts'] > iso_cutoff).groupby('unique_id').mean()\n",
    "    temp_tumor.name = 'tumor_til_fraction'\n",
    "    df['overall_til_fraction'] = temp_overall\n",
    "    df['tumor_til_fraction'] = temp_tumor\n",
    "    df['til_iso_cutoff'] = iso_cutoff\n",
    "    iso_comparison.append(df)\n",
    "\n",
    "iso_comparison = pd.concat(iso_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine info to synthesize further labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>diff_category</th>\n",
       "      <th>major</th>\n",
       "      <th>minor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-3Z-A93Z</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A3-3306</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A3-3308</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A3-3311</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A3-3316</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profile_1096511</th>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profile_1096516</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profile_1096695</th>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profile_1096876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profile_1097026</th>\n",
       "      <td>19.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "diff_category    major  minor\n",
       "unique_id                    \n",
       "TCGA-3Z-A93Z       0.0    2.0\n",
       "TCGA-A3-3306       0.0   20.0\n",
       "TCGA-A3-3308       8.0    5.0\n",
       "TCGA-A3-3311       1.0    0.0\n",
       "TCGA-A3-3316       0.0    6.0\n",
       "...                ...    ...\n",
       "profile_1096511   15.0   24.0\n",
       "profile_1096516    1.0    4.0\n",
       "profile_1096695   12.0   10.0\n",
       "profile_1096876    0.0    2.0\n",
       "profile_1097026   19.0   16.0\n",
       "\n",
       "[1001 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_edge_info_store.value_counts(['unique_id','diff_category']).reset_index().pivot_table(index='unique_id', columns='diff_category')[0].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_minor_edge_agg = weighted_edge_info_store.value_counts(['unique_id','expansion_dist','diff_category']).reset_index().pivot_table(index=['unique_id','expansion_dist'], columns='diff_category')[0].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_minor_edge_agg = major_minor_edge_agg.groupby('unique_id').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>diff_category</th>\n",
       "      <th>major</th>\n",
       "      <th>minor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-3Z-A93Z</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A3-3306</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A3-3308</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A3-3311</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A3-3316</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "diff_category  major  minor\n",
       "unique_id                  \n",
       "TCGA-3Z-A93Z     0.0    1.0\n",
       "TCGA-A3-3306     0.0   10.0\n",
       "TCGA-A3-3308     2.0    2.0\n",
       "TCGA-A3-3311     1.0    0.0\n",
       "TCGA-A3-3316     0.0    4.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "major_minor_edge_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using native count format data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "all_foci_infiltrated        370\n",
       "some_foci_noninfiltrated    182\n",
       "Name: total_foci_infiltration_label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarize_count_info = False\n",
    "\n",
    "# combined_metrics = metrics.copy()\n",
    "# combined_metrics = feature_subset.drop(columns=['tumor_til_fraction']).join(iso_comparison.loc[iso_comparison.til_iso_cutoff == TIL_ISO_CUTOFF,'tumor_til_fraction'])\n",
    "combined_metrics = metrics.copy()\n",
    "combined_metrics = combined_metrics.join(iso_comparison.loc[iso_comparison.til_iso_cutoff == TIL_ISO_CUTOFF,'tumor_til_fraction'])\n",
    "\n",
    "if binarize_count_info:\n",
    "    print('using binarized count info')\n",
    "    raise NotImplementedError\n",
    "else:\n",
    "    print('using native count format data')\n",
    "#     combined_metrics = combined_metrics.drop(columns=updated_count_stats.columns).join(updated_count_stats)\n",
    "    combined_metrics = combined_metrics.join(updated_count_stats)\n",
    "\n",
    "# new / reworked\n",
    "combined_metrics['major_diff_edge_count'] = major_minor_edge_agg['major']\n",
    "combined_metrics['minor_diff_edge_count'] = major_minor_edge_agg['minor']\n",
    "combined_metrics['major_diff_edge_count'] = combined_metrics['major_diff_edge_count'].fillna(0)\n",
    "combined_metrics['minor_diff_edge_count'] = combined_metrics['minor_diff_edge_count'].fillna(0)\n",
    "\n",
    "combined_metrics['any_major_edge'] = (combined_metrics['major_diff_edge_count'] > 0).map({False:'not_present', True:'present'})\n",
    "combined_metrics['any_minor_edge'] = (combined_metrics['minor_diff_edge_count'] > 0).map({False:'not_present', True:'present'})\n",
    "combined_metrics['any_rag_edge'] = ((combined_metrics['major_diff_edge_count'] + combined_metrics['minor_diff_edge_count']) > 0).map({False:'not_present', True:'present'})\n",
    "\n",
    "combined_edge_context_similar_cols = [x for x in count_store['combined_edge_context_count'].columns if (('both' in x) | ('same' in x)) & ('non' not in x)]\n",
    "combined_edge_context_dif_cols = count_store['combined_edge_context_count'].columns.difference(combined_edge_context_similar_cols)\n",
    "\n",
    "subset = combined_metrics.reindex(list(til_context_agg.index.levels[0]))\n",
    "subset['similar_infiltration_along_rag_count'] = subset[combined_edge_context_similar_cols].sum(1)\n",
    "subset['diff_infiltration_along_rag_count'] = subset[combined_edge_context_dif_cols].sum(1)\n",
    "\n",
    "subset.loc[(subset['similar_infiltration_along_rag_count'] > 0) & (subset['diff_infiltration_along_rag_count'] == 0), 'rag_differential_infiltration_label'] = 'all_similar_any_infiltration_along_rag_edges'\n",
    "subset.loc[subset['same_non_bordering_non'] > 0, 'rag_differential_infiltration_label'] = 'all_similar_noninfiltration_along_rag_edges'\n",
    "\n",
    "subset.loc[(subset['similar_infiltration_along_rag_count'] == 0) & (subset['diff_infiltration_along_rag_count'] > 0), 'rag_differential_infiltration_label'] = 'all_differential_along_rag_edges'\n",
    "subset.loc[(subset['similar_infiltration_along_rag_count'] > 0) & (subset['diff_infiltration_along_rag_count'] > 0), 'rag_differential_infiltration_label'] = 'mixed_differential_along_rag_edges'\n",
    "subset.loc[(subset['similar_infiltration_along_rag_count'] == 0) & (subset['diff_infiltration_along_rag_count'] == 0), 'rag_differential_infiltration_label'] = 'other'\n",
    "\n",
    "##########\n",
    "subset['rag_differential_infiltration_label_broad'] = subset['rag_differential_infiltration_label']\n",
    "crit = (subset['rag_differential_infiltration_label'] == 'all_differential_along_rag_edges') | (subset['rag_differential_infiltration_label'] == 'mixed_differential_along_rag_edges')\n",
    "subset.loc[crit, 'rag_differential_infiltration_label_broad'] = 'any_differential_along_rag_edges'\n",
    "\n",
    "##########\n",
    "crit = (subset['any_rag_edge'] == 'not_present') & (subset['isolated_infiltrated'] == 0) & (subset['isolated_noninfiltrated'] > 0)\n",
    "subset.loc[crit, 'isolation_infiltration_summary'] = 'all_isolated_noninfiltrated'\n",
    "\n",
    "crit = (subset['any_rag_edge'] == 'not_present') & (subset['isolated_infiltrated'] > 0) & (subset['isolated_noninfiltrated'] == 0)\n",
    "subset.loc[crit, 'isolation_infiltration_summary'] = 'all_isolated_infiltrated'\n",
    "\n",
    "crit = (subset['any_rag_edge'] == 'not_present') & (subset['isolated_infiltrated'] > 0) & (subset['isolated_noninfiltrated'] > 0)\n",
    "subset.loc[crit, 'isolation_infiltration_summary'] = 'isolated_mixed_infiltration'\n",
    "\n",
    "##########\n",
    "crit = (subset['any_rag_edge'] == 'not_present') & (subset['isolated_infiltrated'] > 0) & (subset['isolated_noninfiltrated'] == 0)\n",
    "subset.loc[crit, 'isolation_all_infiltrated'] = 'all_isolated_infiltrated'\n",
    "\n",
    "crit = (subset['any_rag_edge'] == 'not_present') & (subset['isolated_noninfiltrated'] > 0)\n",
    "subset.loc[crit, 'isolation_all_infiltrated'] = 'isolated_mixed_or_noninfiltrated'\n",
    "\n",
    "##########\n",
    "subset['isolation_all_infiltrated'] = subset['isolation_all_infiltrated'].fillna('other')\n",
    "\n",
    "##########\n",
    "subset.loc[(subset['any_rag_edge'] == 'present'), 'combined_rag_differential_label'] = subset.loc[(subset['any_rag_edge'] == 'present'), 'rag_differential_infiltration_label_broad']\n",
    "subset.loc[(subset['any_rag_edge'] == 'not_present'), 'combined_rag_differential_label'] = subset.loc[(subset['any_rag_edge'] == 'not_present'), 'isolation_all_infiltrated']\n",
    "\n",
    "subset['total_noninfiltrated_foci'] = updated_count_stats[['nonisolated_noninfiltrated','isolated_noninfiltrated']].sum(1)\n",
    "subset['total_infiltrated_foci'] = updated_count_stats[['nonisolated_infiltrated','isolated_infiltrated']].sum(1)\n",
    "\n",
    "crit = (subset['total_noninfiltrated_foci'] > 0 )\n",
    "subset.loc[crit, 'total_foci_infiltration_label'] = 'some_foci_noninfiltrated'\n",
    "\n",
    "crit = (subset['total_infiltrated_foci'] > 0) * (subset['total_noninfiltrated_foci'] == 0 )\n",
    "subset.loc[crit, 'total_foci_infiltration_label'] = 'all_foci_infiltrated'\n",
    "\n",
    "subset['total_foci_infiltration_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(subset['total_infiltrated_foci'] == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Ignore??] Pare down some of the features in RAG set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize_count_info = False\n",
    "# feature_subset = metrics.copy()\n",
    "# feature_subset = feature_subset.join(iso_comparison.loc[iso_comparison.til_iso_cutoff == 10,'tumor_til_fraction'])\n",
    "# feature_subset = feature_subset.join(stromal_til_description_basic)\n",
    "\n",
    "# if binarize_count_info:\n",
    "#     print('using binarized count info and limiting to columns with at least 10% labels == present')\n",
    "#     binarized_count_col_subset = get_indices((updated_count_stats_bool == 'present').mean() >= 0.1)\n",
    "#     feature_subset = feature_subset.join(updated_count_stats_bool[binarized_count_col_subset])\n",
    "# else:\n",
    "#     print('using native count format data')\n",
    "#     feature_subset = feature_subset.join(updated_count_stats)\n",
    "\n",
    "# feature_subset = feature_subset.join(subset['combined_rag_differential_label'])\n",
    "# feature_subset = feature_subset.join(subset['total_foci_infiltration_label'])\n",
    "# feature_subset = feature_subset.join(subset[['diff_infiltration_along_rag_count','similar_infiltration_along_rag_count']])\n",
    "\n",
    "# feature_subset['any_major_edge'] = (feature_subset['major_diff_edge_count'] > 0).map({False:'not_present', True:'present'})\n",
    "# feature_subset['any_minor_edge'] = (feature_subset['minor_diff_edge_count'] > 0).map({False:'not_present', True:'present'})\n",
    "# feature_subset['any_rag_edge'] = ((feature_subset['major_diff_edge_count'] + feature_subset['minor_diff_edge_count']) > 0).map({False:'not_present', True:'present'})\n",
    "# feature_subset['rag_edge_total'] = feature_subset['minor_diff_edge_count'] + feature_subset['major_diff_edge_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: 'combined_rag_differential_label' causing big loss of CM025 cases when following previous removal of cases that == 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_agg = []\n",
    "for uid in weighted_edge_info_store.index.levels[0]:\n",
    "    try:\n",
    "        seg_df = tilewise_nontil_info.loc[[uid]]\n",
    "        edge_subset = weighted_edge_info_store.loc[[uid]]\n",
    "        edge_subset = check_label_set_df(seg_df, edge_subset)\n",
    "        edge_agg.append(edge_subset)\n",
    "    except:\n",
    "        print(f'{uid} failed to aggregate')\n",
    "\n",
    "edge_agg = pd.concat(edge_agg)\n",
    "\n",
    "# fix object dtype assignment\n",
    "for col in edge_agg.columns:\n",
    "    try:\n",
    "        edge_agg[col] = edge_agg[col].astype(float)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### skip over `feature_subset` and use `combined_metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_subset = combined_metrics.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Segment-Wise Mean Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentwise_mean = tilewise_nontil_info.loc[tilewise_nontil_info.meta !='stroma'].groupby(['unique_id','merged_labels']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Proximal vs Distal Edges & Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_agg_pivot = edge_agg.reset_index().pivot_table(index=['unique_id','edge0','edge1','passing_edge'], columns='expansion_dist', values=['diff','tumor_area_frac_sum'])\n",
    "edge_agg_pivot = edge_agg_pivot.reset_index(level=3)\n",
    "edge_agg_pivot['passing_edge'] = edge_agg_pivot['passing_edge'].astype(bool)\n",
    "edge_agg_pivot['edge_class'] = edge_agg_pivot['diff'].apply(lambda x: classify_distal_vs_proximal_edge(x), 1)\n",
    "edge_agg_pivot.loc[~edge_agg_pivot['passing_edge'], 'edge_class'] = 'not_eligible'\n",
    "edge_agg_pivot['edge_class'] = edge_agg_pivot['edge_class'].fillna('not_eligible')\n",
    "\n",
    "edge_class_sum = pd.get_dummies(edge_agg_pivot, columns=['edge_class']).groupby('unique_id').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add node0/1 annotations to each edge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seg_counts = tilewise_nontil_info.loc[tilewise_nontil_info['meta'] == 'tumor'].value_counts(subset=['unique_id','merged_labels'])\n",
    "all_seg_counts.name = 'seg_size'\n",
    "all_seg_counts = pd.DataFrame(all_seg_counts).join(segmentwise_mean['smoothed_prob_g4_not_g2']) # add segment mean grade score\n",
    "all_seg_counts = all_seg_counts.reset_index()\n",
    "all_seg_counts['seg_area_frac'] = all_seg_counts.groupby(['unique_id']).seg_size.apply(lambda x: x/x.sum())\n",
    "all_seg_counts['merged_labels'] = all_seg_counts['merged_labels'].astype(int)\n",
    "\n",
    "edge_agg_pivot = edge_agg_pivot.reset_index(level=1)\n",
    "edge_agg_pivot.index.set_names('merged_labels',level=1, inplace=True)\n",
    "edge_agg_pivot = edge_agg_pivot[['edge0','edge_class']]\n",
    "edge_agg_pivot.columns = [' '.join(col).strip() for col in edge_agg_pivot.columns.values]\n",
    "\n",
    "# add node 1 info \n",
    "edge_agg_pivot = edge_agg_pivot.join(all_seg_counts.set_index(['unique_id','merged_labels'])).rename(columns={'seg_area_frac':'node1_area_frac', 'smoothed_prob_g4_not_g2':'node1_grade_score'})\n",
    "edge_agg_pivot = edge_agg_pivot.join(til_context_agg).rename(columns={x:'node1_'+x for x in til_context_agg.columns})\n",
    "\n",
    "edge_agg_pivot.index.set_names('edge1',level=1, inplace=True)\n",
    "edge_agg_pivot = reset_set_idx(edge_agg_pivot, ['unique_id','edge0'])\n",
    "edge_agg_pivot.index.set_names('merged_labels',level=1, inplace=True)\n",
    "\n",
    "# add node 0 info \n",
    "edge_agg_pivot = merge_nonoverlapping(edge_agg_pivot, all_seg_counts.set_index(['unique_id','merged_labels'])).rename(columns={'seg_area_frac':'node0_area_frac' ,'smoothed_prob_g4_not_g2':'node0_grade_score'})\n",
    "edge_agg_pivot = edge_agg_pivot.join(til_context_agg).rename(columns={x:'node0_'+x for x in til_context_agg.columns})\n",
    "\n",
    "edge_agg_pivot.index.set_names('edge0',level=1, inplace=True)\n",
    "edge_agg_pivot = reset_set_idx(edge_agg_pivot, ['unique_id','edge0','edge1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add an F1 style measure of the node area fractions \n",
    "- If close to 1, it's a balanced edge; closer to 0 implies one of the nodes is much smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_agg_pivot['edge_pair_area'] = edge_agg_pivot['node0_area_frac'] + edge_agg_pivot['node1_area_frac']\n",
    "edge_agg_pivot['min_node_area_in_edge'] = edge_agg_pivot[['node0_area_frac', 'node1_area_frac']].apply(min, 1)\n",
    "\n",
    "ec_recover = edge_agg_pivot['edge_class'].copy()\n",
    "edge_agg_pivot = pd.get_dummies(edge_agg_pivot, columns=['edge_class'])\n",
    "edge_agg_pivot['edge_class'] = ec_recover\n",
    "\n",
    "edge_agg_pivot['area_fmeasure'] = 4*(edge_agg_pivot['node0_area_frac']*edge_agg_pivot['node1_area_frac'])/(edge_agg_pivot['node0_area_frac']+edge_agg_pivot['node1_area_frac'])\n",
    "\n",
    "edge_agg_pivot['edge_class_distal_min_weighted'] = edge_agg_pivot['min_node_area_in_edge'] * edge_agg_pivot['edge_class_distal']\n",
    "edge_agg_pivot['edge_class_proximal_min_weighted'] = edge_agg_pivot['min_node_area_in_edge'] * edge_agg_pivot['edge_class_proximal']\n",
    "\n",
    "edge_agg_pivot['edge_class_distal_total_weighted'] = edge_agg_pivot['edge_pair_area'] * edge_agg_pivot['edge_class_distal']\n",
    "edge_agg_pivot['edge_class_proximal_total_weighted'] = edge_agg_pivot['edge_pair_area'] * edge_agg_pivot['edge_class_proximal']\n",
    "\n",
    "edge_agg_pivot['edge_class_distal_f_weighted'] = edge_agg_pivot['area_fmeasure'] * edge_agg_pivot['edge_class_distal']\n",
    "edge_agg_pivot['edge_class_proximal_f_weighted'] = edge_agg_pivot['area_fmeasure'] * edge_agg_pivot['edge_class_proximal']\n",
    "\n",
    "edge_agg_pivot = edge_agg_pivot.dropna(subset=['node1_area_frac','node0_area_frac'])\n",
    "edge_class_sum = edge_agg_pivot.iloc[:,5:].groupby('unique_id').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push to file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tilewise_til_info.to_csv('./rerun_tilewise_grade_til_annotations.csv')\n",
    "tilewise_nontil_info.to_csv('./rerun_tilewise_grade_nontil_annotations.csv')\n",
    "\n",
    "merged_descriptions.to_csv('./rerun_node_descriptions.csv')\n",
    "feature_subset.to_csv('./rerun_additional_feature_subset.csv')\n",
    "weighted_edge_info_store.to_csv('./rerun_base_rag_edge_info_annotation.csv')\n",
    "\n",
    "edge_agg.to_csv('./rerun_base_rag_edge_info_raw__edge_agg.csv')\n",
    "edge_agg_pivot.to_csv('./rerun_base_rag_edge_info_annotation_processed.csv')\n",
    "edge_class_sum.to_csv('./rerun_base_rag_edge_info_annotation_processed_sum.csv')\n",
    "\n",
    "til_context_agg.to_csv('./rerun_segmentwise_til_context_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2300577, 33)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tilewise_til_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4720757, 16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tilewise_nontil_info.shape"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m56"
  },
  "kernelspec": {
   "display_name": "pathml",
   "language": "python",
   "name": "pathml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
